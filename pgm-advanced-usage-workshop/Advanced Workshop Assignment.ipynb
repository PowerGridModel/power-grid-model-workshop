{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a727ce38",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment you will be given a series of tasks about using the library `power-grid-model`. The agenda includes:\n",
    "\n",
    "* Load input (From Power flow assignment)\n",
    "* Numpy tips and PGM related recommendations\n",
    "* Types of Dataset\n",
    "* Miscellaneous PGM features\n",
    "* Selective output\n",
    "* Complex Simulations\n",
    "    * Multiple Timeseries\n",
    "    * Side topic: PGM DS library\n",
    "    * Contingency Analysis\n",
    "        * Topology caching\n",
    "        * Simulation design exercise\n",
    "    * Dynamic operating Envelope\n",
    "        * Simulation design exercise\n",
    "    * Additional content\n",
    "        * Simulation design exercise\n",
    "\n",
    "Throughout this notebook there are big notebook cells of code. \n",
    "To have a deeper understanding of the simulations, it is recommended to comment it all and uncomment line by line along with confirming the debugging print statements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b18d109c",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "First import everything we need for this workshop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc50a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from power_grid_model import (\n",
    "    PowerGridModel,\n",
    "    CalculationType,\n",
    "    CalculationMethod,\n",
    "    ComponentType,\n",
    "    DatasetType,\n",
    "    initialize_array,\n",
    "    attribute_dtype,\n",
    "    attribute_empty_value,\n",
    "    power_grid_meta_data\n",
    ")\n",
    "\n",
    "from power_grid_model.validation import assert_valid_input_data, assert_valid_batch_data\n",
    "\n",
    "from power_grid_model_ds import PowerGridModelInterface\n",
    "from power_grid_model_ds.enums import NodeType\n",
    "from power_grid_model_ds.visualizer import visualize\n",
    "\n",
    "from utils import Timer\n",
    "import psutil\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687985dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab4fd44",
   "metadata": {},
   "source": [
    "# Topology Data and Timeseries load profiles \n",
    "\n",
    "(Reused from Power flow assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb462396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_data() -> dict[str, np.ndarray]:\n",
    "    input_data = {}\n",
    "    for component in [\n",
    "        ComponentType.node,\n",
    "        ComponentType.line,\n",
    "        ComponentType.source,\n",
    "        ComponentType.sym_load,\n",
    "    ]:\n",
    "        # Use pandas to read CSV data\n",
    "        df = pd.read_csv(f\"../data/{component.value}.csv\")\n",
    "\n",
    "        # Initialize array\n",
    "        input_data[component] = initialize_array(DatasetType.input, component, len(df))\n",
    "\n",
    "        # Fill the attributes\n",
    "        for attr, values in df.items():\n",
    "            input_data[component][attr] = values\n",
    "\n",
    "        # Print some debug info\n",
    "        print(f\"{component:9s}: {len(input_data[component]):4d}\")\n",
    "\n",
    "    return input_data\n",
    "\n",
    "\n",
    "input_data = load_input_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e571c",
   "metadata": {},
   "source": [
    "Create a PowerGridModel instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf581717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PowerGridModel(input_data=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791a9c9",
   "metadata": {},
   "source": [
    "Lets use these number timestamps for all calculations in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e89607",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timestamps = 24 * 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe924e2",
   "metadata": {},
   "source": [
    "We use same timeseries profile as in the Power Flow assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random load profile oh hourly data\n",
    "dti = pd.date_range(\"2022-01-01\", periods=n_timestamps, freq=\"h\")\n",
    "n_loads = len(input_data[ComponentType.sym_load])\n",
    "load_id = input_data[ComponentType.sym_load][\"id\"]\n",
    "load_p = input_data[ComponentType.sym_load][\"p_specified\"]\n",
    "profile = np.tile(load_p, (n_timestamps, 1)) + 1e5 * np.random.randn(\n",
    "    n_timestamps, n_loads\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daad8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty load profile\n",
    "load_profile_row_based = initialize_array(\n",
    "    DatasetType.update, ComponentType.sym_load, profile.shape\n",
    ")\n",
    "\n",
    "load_profile_row_based[\"id\"] = load_id\n",
    "load_profile_row_based[\"p_specified\"] = profile\n",
    "load_profile_row_based[\"q_specified\"] = 0.0\n",
    "\n",
    "# Construct the update data\n",
    "update_data_row_based = {ComponentType.sym_load: load_profile_row_based}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c60cd",
   "metadata": {},
   "source": [
    "# Side topics related to numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25ed1b",
   "metadata": {},
   "source": [
    "## Calcualting Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c818b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"Current memory usage: {mem_info.rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "\n",
    "def print_memory_used_by_object(object):\n",
    "    print(f\"Memory used by object: {object.__sizeof__() / 1024 / 1024} MB\")\n",
    "\n",
    "\n",
    "def print_memory_used_by_dict(dictionary):\n",
    "    print(\n",
    "        f\"Memory used by dictionary: {sum(object.__sizeof__() / 1024 / 1024 for object in dictionary.values())} MB\"\n",
    "    )\n",
    "\n",
    "\n",
    "def print_memory_used_by_array(array: np.ndarray):\n",
    "    print(f\"Memory used by numpy array: {array.nbytes / 1024 / 1024} MB\")\n",
    "\n",
    "\n",
    "print_memory_usage()\n",
    "\n",
    "print_memory_used_by_object([1] * 1000)\n",
    "print_memory_used_by_object(\n",
    "    {\"a\": [1] * 1000}\n",
    ")  # This is because dictionary stores only references\n",
    "\n",
    "print_memory_used_by_dict({\"a\": [1] * 1000})\n",
    "\n",
    "print_memory_used_by_array(np.random.rand(1000, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e707b9",
   "metadata": {},
   "source": [
    "## Correct dtype for PGM arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d3c13",
   "metadata": {},
   "source": [
    "\n",
    "Use of initialize_array is recommended for most uses.\n",
    "The reasoning for this recommendation should be clear by the end of this workshop.\n",
    "\n",
    "However if you wish to translate the dtype into the one PGM uses, you can use  `initialize_array(dataset_type, component_type, empty_shape, empty=True)` or `dtype = power_grid_meta_data[dataset_type][component_type].dtype` to find the dtype of the row based data. You can use this to change to the appropriate type which is required by PGM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_array(DatasetType.input, ComponentType.sym_load, 0, empty=True)\n",
    "# power_grid_meta_data[DatasetType.input][ComponentType.sym_load].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ac8f3",
   "metadata": {},
   "source": [
    "For dtype of individual attribute which would be required in columnar data creation, you can use `attribute_dtype(data_type, component_type, attribute)`. The missing value can be filled by `attribute_empty_value(data_type, component_type, attribute)` \n",
    "\n",
    "Tip: Check if a type-cast to this dtype creates a copy. Maybe such a copy is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_dtype(DatasetType.input, ComponentType.transformer, \"sn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c9251",
   "metadata": {},
   "source": [
    "All available attributes are visible via following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_array(DatasetType.input, ComponentType.sym_load, 0, empty=True).dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8ef68",
   "metadata": {},
   "source": [
    "## Views, copies and Memory location\n",
    "\n",
    "A view is a windowed look into an array. Creating views is very inexpensive. \n",
    "A copy here is meant by an array which owns the data within it.\n",
    "\n",
    "Check numpy documentation for when certain functions or features create a view or copy. \n",
    "\n",
    "* Views simplify assignment of values to arrays.\n",
    "* Uneccesary copies here are the first you can aim to eliminate to improve overall performance.\n",
    "* Beware of unintentional memory usage because of views.\n",
    "\n",
    "\n",
    "https://numpy.org/doc/stable/user/basics.copies.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b08530",
   "metadata": {},
   "source": [
    "\n",
    "* Checking if view or copy: if `array.base is None` -> copy; else -> view\n",
    "* Finding out view belongs to which original array: if `array.base is original_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(9)\n",
    "y = x.reshape(3, 3)\n",
    "assert y.base is not None  # .reshape() creates a view\n",
    "\n",
    "z = y[[2, 1]]\n",
    "assert z.base is None  # advanced indexing creates a copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168a6e4",
   "metadata": {},
   "source": [
    "## Garbage collection for views/copies\n",
    "\n",
    "### Holding base array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_give_first_50_loading(model, update_data):\n",
    "    output_data = model.calculate_power_flow(\n",
    "        update_data=update_data,\n",
    "        calculation_method=CalculationMethod.newton_raphson\n",
    "    )\n",
    "    return output_data[ComponentType.line][\"loading\"][:50]\n",
    "\n",
    "\n",
    "first_50_loading = calculate_and_give_first_50_loading(model, update_data_row_based)\n",
    "\n",
    "\n",
    "print(f\"Shape of returned array: {first_50_loading.shape}\")\n",
    "print_memory_used_by_array(first_50_loading)\n",
    "\n",
    "print(f\"Actual shape of memory: {first_50_loading.base.shape}\")\n",
    "print_memory_used_by_array(first_50_loading.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75552bf8",
   "metadata": {},
   "source": [
    "Use .copy() to convert a view into a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_give_first_50_loading(model, update_data):\n",
    "    output_data = model.calculate_power_flow(\n",
    "        update_data=update_data,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        threading=0\n",
    "    )\n",
    "    return output_data[ComponentType.line][\"loading\"][:50].copy()\n",
    "\n",
    "\n",
    "first_50_loading = calculate_and_give_first_50_loading(model, update_data_row_based)\n",
    "print(f\"Shape of returned array: {first_50_loading.shape}\")\n",
    "print_memory_used_by_array(first_50_loading)\n",
    "assert first_50_loading.base is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573d0f4",
   "metadata": {},
   "source": [
    "## Data Contiguity\n",
    "\n",
    "What is Contiguity in numpy arrays?\n",
    "- Contiguity means all array elements are laid out sequentially in memory.\n",
    "    - C contiguous: row major where rows are stored one after another. ie. All elements are in order of right to left dimension. Rightmost dimension is fast changing. (This is default in numpy and also required by PGM.)\n",
    "    - F contiguous: column-major where columns stored one after another. ie. All elements are in order of left to right dimension. Leftmost dimension is fast changing.\n",
    "\n",
    "The input and update dataset needs to be a C contigious dataset before PGM can make use of it. While PGM output is C contigious. PGM internally converts it to be C contigious if its not.\n",
    "\n",
    "A basic sliced dataset would retain contiguity. Whereas a transposed or advanced sliced array would not.\n",
    "A reshaped dataset mostly would be C contigious.\n",
    "\n",
    "Check `arr.flags` for Contiguity.\n",
    "This requirement for PGM and for further uses can be pre-planned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = np.zeros((1000, 10),dtype=np.float64)\n",
    "print(f\"1. {loads.flags}\")\n",
    "print(f\"2. {loads.reshape(10, 20, 50).flags}\")\n",
    "print(f\"3. {loads.T.flags}\")\n",
    "print(f\"5. {np.transpose(loads.reshape(10, 20, 50), axes=(2, 0, 1)).flags}\")\n",
    "\n",
    "print(f\"4. {np.ascontiguousarray(loads) is loads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a03ce",
   "metadata": {},
   "source": [
    "`initialize_array` handles contiguity and dtype requirement for row based data without user having to think about it. \n",
    "For columnar data however the responsibility lies with the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097bc587",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Does a view own its data?\n",
    "- Give reasoning for flags of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3eed3",
   "metadata": {},
   "source": [
    "## Accessing and assigning to PGM arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e9f0d2",
   "metadata": {},
   "source": [
    "PGM component has layout of (scenarios, components in a scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = initialize_array(DatasetType.update, ComponentType.sym_load, (1000, 10))\n",
    "loads[:] = (99, 1, 100.0, 100.0)\n",
    "\n",
    "def copy_or_view(arr: np.ndarray) -> str:\n",
    "    return \"copy\" if arr.base is None else \"view\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f38b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Single batch all components: `loads[:, 0]` gets a :\", copy_or_view(loads[:, 0]))\n",
    "print(\"All batch single components: `loads[0, :]` gets a :\", copy_or_view(loads[0, :]))\n",
    "print(\"Sliced batch all components: `loads[:5, :]` gets a :\", copy_or_view(loads[:5, :]))\n",
    "print(\"Multiple batch via advanced indexing all components: `loads[[1,2,3], :]` gets a :\", copy_or_view(loads[[1,2,3], :]))  # Advanced indexing creates a copy\n",
    "print(\"All batch Multiple components via advanced indexing: `loads[:, [1,2,3]]` gets a :\", copy_or_view(loads[:, [1,2,3]]))  # Deceptive: view of another copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b16212",
   "metadata": {},
   "source": [
    "### Attribute access\n",
    "\n",
    "Attribute access has similar behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3191ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Single batch all components: `loads['p_specified']` gets a :\", copy_or_view(loads[\"p_specified\"]))\n",
    "print(\"Single batch all components: `loads['p_specified'][:,0]` gets a :\", copy_or_view(loads[\"p_specified\"][:, 0]))\n",
    "print(\"Single batch all components: `loads['p_specified'][0, :]` gets a :\", copy_or_view(loads[\"p_specified\"][0, :]))\n",
    "print(\"Sliced batch all components: `loads['p_specified'][:5, :]` gets a :\", copy_or_view(loads[\"p_specified\"][:5, :]))\n",
    "print(\"Single batch all components: `loads['p_specified'][[1, 2, 3], :]` gets a :\", copy_or_view(loads[\"p_specified\"][[1, 2, 3], :]))\n",
    "print(\"Single batch all components: `loads['p_specified'][:, [1, 2, 3]]` gets a :\", copy_or_view(loads[\"p_specified\"][:, [1, 2, 3]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f6fd1c",
   "metadata": {},
   "source": [
    "Its recommended to index with field first (`loads[\"p_specified\"][...]` instead of `loads[...][\"p_specified\"]`) because advanced indexing on structured arrays can create copies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc7376",
   "metadata": {},
   "source": [
    "Multi field indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4114e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multiple attributes: `loads[['p_specified', 'q_specified']][:, [1, 2, 3]]` gets a :\", copy_or_view(loads[[\"p_specified\", \"q_specified\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f5b9d",
   "metadata": {},
   "source": [
    "A common source of confusion is when dealing with numpy arrays view and copy variables. They look the same. \n",
    "* Modifications on view modifies the view as well as the original array.\n",
    "* Modifications on copy modifies only that copy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = initialize_array(DatasetType.update, ComponentType.sym_load, (1000, 4))\n",
    "loads[:] = (99, 1, 100.0, 100.0)\n",
    "\n",
    "x = loads[\"p_specified\"][:3, :]\n",
    "loads[\"p_specified\"][:3, :] = 123456\n",
    "print(x)\n",
    "print(x.base is loads)  # x is a view of loads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = initialize_array(DatasetType.update, ComponentType.sym_load, (1000, 4))\n",
    "loads[:] = (99, 1, 100.0, 100.0)\n",
    "\n",
    "x = loads[\"p_specified\"][[1, 2, 3], :]\n",
    "loads[\"p_specified\"][[1, 2, 3], :] = 123456\n",
    "print(x)\n",
    "print(x.base is loads)  # x is a copy of the loadings of scenario 1 2 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95af8880",
   "metadata": {},
   "source": [
    "#### Deceiptive: It was a view of a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = initialize_array(DatasetType.update, ComponentType.sym_load, (1000, 4))\n",
    "loads[:] = (99, 1, 100.0, 100.0)\n",
    "\n",
    "x = loads[\"p_specified\"][:, [1, 2, 3]]\n",
    "loads[\"p_specified\"][:, [1, 2, 3]] = 123456\n",
    "print(x)\n",
    "print(x.base is loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab922bf6",
   "metadata": {},
   "source": [
    "### Assignment to arrays\n",
    "\n",
    "Assigning means setting values to the array.\n",
    "\n",
    "#### Via tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008513ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = initialize_array(DatasetType.input, ComponentType.asym_load, (10, 6))\n",
    "loads[\"p_specified\"] = 1000\n",
    "loads[\"p_specified\"] = [[1000], [1000], [1000], [1000], [1000], [1000]]\n",
    "# fields are in this order: ('id', 'node', 'status', 'type', 'p_specified', 'q_specified')\n",
    "loads[:, 0] = (1, 2, 1, 0, 123, 0)\n",
    "loads[:] = (1, 2, 1, 0, 123, 0)\n",
    "loads[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e96401",
   "metadata": {},
   "source": [
    "Reshaping the destination arrays is also possible since a view gets created.\n",
    "Its possible to assign values this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = initialize_array(DatasetType.input, ComponentType.asym_load, (10, 6))\n",
    "reshaped_loads = loads.reshape(2, 5, 6)\n",
    "reshaped_loads[0, :, :] = (1, 2, 1, 0, 123, 0)\n",
    "reshaped_loads[1, :, :] = (3, 4, 5, 0, 456, 0)\n",
    "loads[[2, -2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696572d9",
   "metadata": {},
   "source": [
    "Use functions with out parameter to write results directly into pre-allocated arrays. for eg. arrays created via initialize_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036537fe",
   "metadata": {},
   "source": [
    "# Types of datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d4a87",
   "metadata": {},
   "source": [
    "### Row based format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_memory_used_by_array(update_data_row_based[ComponentType.sym_load])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Newton Raphson power flow (this may take a minute...)\n",
    "with Timer(\"Batch Calculation using Newton-Raphson row based data\"):\n",
    "    output_data = model.calculate_power_flow(\n",
    "        update_data=update_data_row_based,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        threading=0,\n",
    "    )\n",
    "\n",
    "print_memory_used_by_dict(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63af797",
   "metadata": {},
   "source": [
    "### Columnar data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the update data\n",
    "update_data_columnar = {ComponentType.sym_load: {\"p_specified\": profile}}\n",
    "\n",
    "print_memory_used_by_array(profile)  # in MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796441d",
   "metadata": {},
   "source": [
    "PGM Columnar data is all attributes array are fed in indvidually as separate arrays.\n",
    "This enables us to skip empty or redundant attribute data.\n",
    "Skipping ids is also possible under certain conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be73996",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Batch Calculation using Newton-Raphson columnar data\"):\n",
    "    output_data = model.calculate_power_flow(\n",
    "        update_data=update_data_columnar,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        threading=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3197e",
   "metadata": {},
   "source": [
    "### Selective Output\n",
    "\n",
    "It is possible to output only selected attributes via output_component_types. The effect on memory usage is huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Batch Calculation using Newton-Raphson columnar data\"):\n",
    "    output_data_selective = model.calculate_power_flow(\n",
    "        update_data=update_data_columnar,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        output_component_types={ComponentType.line: [\"loading\"]},\n",
    "        threading=0\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"output_data_selective contains following: \\n\"\n",
    "    f\"Keys: {output_data_selective.keys()}. \\n\"\n",
    "    f\"Attributes: {output_data_selective[ComponentType.line].keys()}\"\n",
    ")\n",
    "print_memory_used_by_array(output_data_selective[ComponentType.line][\"loading\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0338fdb",
   "metadata": {},
   "source": [
    "Lets define all limit related attributes to use in upcoming simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_related_output = {\n",
    "    ComponentType.line: [\"loading\"],\n",
    "    ComponentType.node: [\"u_pu\"],\n",
    "    ComponentType.transformer: [\"loading\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a8ef8",
   "metadata": {},
   "source": [
    "#### Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "del load_profile_row_based, output_data, output_data_selective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5b93e",
   "metadata": {},
   "source": [
    "# Miscellanious PGM features\n",
    "\n",
    "## Sparse datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e731c5",
   "metadata": {},
   "source": [
    "For unequal update sets use linear data + pointers. \n",
    "This way of providing update would likely be a niche.\n",
    "\n",
    "Columnar sparse dataset representation for example can be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aadfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data_sparse = {\n",
    "    ComponentType.line: {\n",
    "        \"indptr\": [0, 1, 1, 2],\n",
    "        \"data\": {\n",
    "            \"p_specified\": [1000, 2000]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c73c4",
   "metadata": {},
   "source": [
    "## Validating large batch data\n",
    "\n",
    "Since the validator for large batch dataset is expensive, we can choose to validate only some part of data.\n",
    "The result of the validator is also difficult to interpret with many errors on a large dataset.\n",
    "Maximum data errors typically occur in the input dataset.\n",
    "Hence we can slice the update data to only certain batches and validate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Validation of full batch data\"):\n",
    "    assert_valid_batch_data(\n",
    "        input_data=input_data,\n",
    "        update_data=update_data_row_based,\n",
    "        calculation_type=CalculationType.power_flow,\n",
    "    )\n",
    "\n",
    "with Timer(\"Validation of partial batch data\"):\n",
    "    assert_valid_batch_data(\n",
    "        input_data=input_data,\n",
    "        update_data={k: v[:5, :] for k, v in update_data_row_based.items()},\n",
    "        calculation_type=CalculationType.power_flow,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10693b81",
   "metadata": {},
   "source": [
    "# Complex simulations\n",
    "\n",
    "Often times we wish to run multiple simulations at once. \n",
    "These power flow calculations have multiple dimensions associated with them where the information regarding that particular simulation is put in.\n",
    "The way to simulate these via PGM most effectively is to flatten all the excess dimension into one, ie. of batches. \n",
    "This makes the entire simulation including and most likely excluding PGM most efficient, readable and less bug-prone.\n",
    "\n",
    "\n",
    "## Multiple Timeseries\n",
    "\n",
    "We are now going to simulate multiple timeseries in a single power flow calculation and later the results would be aggregated from the output numpy arrays.\n",
    "\n",
    "\n",
    "Here we have a EV growth related scenario in a neighbourhood.\n",
    "For this simulation we have yearly EV consumption profiles available for 10 different customers.\n",
    "We shall subset these profiles and timestamps to align with the data in this notebook  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly EV profile data for one year. Row = hours, column = profiles\n",
    "ev_profile = (\n",
    "    pd.read_csv(\"../data/ev_profile.csv\").to_numpy(\n",
    "        dtype=np.float64, copy=False, na_value=np.nan\n",
    "    )\n",
    "    * 1000\n",
    ")  # kw\n",
    "\n",
    "# Select first n_timestamps and first n profiles\n",
    "n_ev_profiles = 10\n",
    "\n",
    "assert n_timestamps <= ev_profile.shape[0]\n",
    "assert n_ev_profiles <= ev_profile.shape[1]\n",
    "ev_profile = ev_profile[:n_timestamps, :n_ev_profiles] # Hint: Slicing\n",
    "print(f\"Shape of ev_profile: {ev_profile.shape}\") # Prints: (n_timestamps * n_ev_profiles) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27520d80",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since the EV growth at each node is uncertain, we can sample different EV growth scenarios.\n",
    "Lets consider: \n",
    "* The maximal EV sales in a region is a known quantity (denoted by n_vehicles).\n",
    "* The spread of EVs across each loaded nodes is equal (denoted by pvals of n_vehicle_each_node).\n",
    "* We conduct n_experiments samples for monte carlo simulation\n",
    "* Each EV profile is assigned to each EV equally random (denoted by pvals of distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de68fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vehicles = 100000\n",
    "n_experiments = 11\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "n_vehicle_each_node = rng.multinomial(\n",
    "    n=..., pvals=[1 / ...] * ..., size=...\n",
    ")\n",
    "print(f\"Shape of n_vehicle_each_node: {n_vehicle_each_node.shape}\") # Prints: (n_experiments * n_loads) \n",
    "\n",
    "distributions = rng.multinomial(\n",
    "    n=n_vehicle_each_node, pvals=[1 / ...] * ..., size=None\n",
    ")\n",
    "print(f\"Shape of distributions: {distributions.shape}\") # Prints: (n_experiments, n_loads, n_ev_profiles) \n",
    "\n",
    "ev_timeseries = np.transpose(... @ (...).T, axes=(0, 2, 1))\n",
    "print(f\"Shape of ev_timeseries: {ev_timeseries.shape}\") # Prints: (n_experiments, n_timestamps, n_loads) \n",
    "\n",
    "ev_timeseries_q = ev_timeseries * ... # assume power factor of 0.95\n",
    "\n",
    "# Hint: broadcasting (n_timestamps, n_loads) to (n_experiments, n_timestamps, n_loads) \n",
    "combined_timeseries = profile[...] + ev_timeseries \n",
    "print(f\"Shape of combined_timeseries: {combined_timeseries.shape}\") # Prints: (n_experiments, n_timestamps, n_loads) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c840b",
   "metadata": {},
   "source": [
    "Create columnar update data and run calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data_multi_timeseries = {\n",
    "    ComponentType.sym_load: {\n",
    "        \"p_specified\": combined_timeseries.reshape(..., ...), # All update data Should be 2D eventually\n",
    "        \"q_specified\":  ev_timeseries.reshape(..., ...),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7618f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Run multitimeseries PF\"):\n",
    "    output_data = model.calculate_power_flow(\n",
    "        update_data=update_data_multi_timeseries,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        output_component_types=limit_related_output,\n",
    "        threading=0\n",
    "    )\n",
    "\n",
    "reshaped_loading_data = output_data[ComponentType.line][\"loading\"].reshape(..., ..., ...)\n",
    "print(f\"Shape of reshaped_loading_data: {reshaped_loading_data.shape}\") # Prints: (n_experiments, n_timestamps, n_loads) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c6f70",
   "metadata": {},
   "source": [
    "Aggregate result on the basis of experiments of monte carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(reshaped_loading_data, axis=...) # Shape: (n_timestamps, n_loads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "del output_data, reshaped_loading_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700eb7ce",
   "metadata": {},
   "source": [
    "When PF is run in loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_id_loop = np.tile(input_data[ComponentType.sym_load][\"id\"], (n_timestamps, 1))\n",
    "output_datas = []\n",
    "with Timer(\"Run multi-timeseries PF in loop\"):\n",
    "    for experiment in range(n_experiments):\n",
    "        update_data_loop = {\n",
    "            ComponentType.sym_load: {\n",
    "                \"id\": load_id_loop,\n",
    "                \"p_specified\": combined_timeseries[experiment, :, :],\n",
    "                \"q_specified\": ev_timeseries_q[experiment, :, :],\n",
    "            }\n",
    "        }\n",
    "        output_data = model.calculate_power_flow(\n",
    "            update_data=update_data_loop,\n",
    "            calculation_method=CalculationMethod.newton_raphson,\n",
    "            output_component_types=limit_related_output,\n",
    "            threading=0,\n",
    "        )\n",
    "        output_datas.append(output_datas)\n",
    "\n",
    "del output_datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea122b",
   "metadata": {},
   "source": [
    "\n",
    "The difference between this method and one big batch is indeed not very large, but this is a significant for performance improvement. \n",
    "\n",
    "The combining/seprating numpy arrays is a lot more wasteful.\n",
    "\n",
    "The calculating of mean on `output_datas` list is more difficult than a numpy array.\n",
    "\n",
    "Always keep the components within a single scenario as the rightmost dimension (aka. fast moving dimension). \n",
    "In this example it would be `n_loads`.\n",
    "A transposing of array would likely be required otherwise which is an extra copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8c8e",
   "metadata": {},
   "source": [
    "## PGM DS library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8b3b4",
   "metadata": {},
   "source": [
    "Converting to and from a PGM DS grid can be done via `PowerGridModelInterface`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8408fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_interface = PowerGridModelInterface(input_data=input_data)\n",
    "grid = core_interface.create_grid_from_input_data()\n",
    "print(grid.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc487324",
   "metadata": {},
   "source": [
    "### Visualization of grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b633f",
   "metadata": {},
   "source": [
    "### Graph operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb32bc",
   "metadata": {},
   "source": [
    "Some graphical operations possible via PGM-DS. Custom ones can be implemented in your simulation via rustworkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab287807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid.node.node_type[0] = NodeType.SUBSTATION_NODE\n",
    "\n",
    "# Downstream nodes from node 1 with the substation node as reference\n",
    "print(f\"1. {grid.get_downstream_nodes(node_id=1)}\")\n",
    "\n",
    "# In case of multiple substations, find nearest one\n",
    "print(f\"2. {grid.get_nearest_substation_node(node_id=10).id}\")\n",
    "\n",
    "# Find all paths between node 1 and node 10\n",
    "print(f\"3. {grid.graphs.active_graph.get_all_paths(ext_start_node_id=1, ext_end_node_id=10)}\")\n",
    "\n",
    "# Find shortest path between node 1 and node 10\n",
    "print(f\"4. {grid.graphs.active_graph.get_shortest_path(ext_start_node_id=1, ext_end_node_id=10)}\")\n",
    "\n",
    "# All components in this graph\n",
    "print(f\"5. {len(grid.graphs.active_graph.get_components())}\")\n",
    "\n",
    "# All components connected to node 1\n",
    "print(f\"6. {len(grid.graphs.active_graph.get_connected(node_id=1))}\")\n",
    "\n",
    "# All components connected to node 0, ignoring nodes 1 and 2\n",
    "print(f\"7. {len(grid.graphs.active_graph.get_connected(node_id=0, nodes_to_ignore=[1, 2]))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb9b25",
   "metadata": {},
   "source": [
    "### Array operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702164d",
   "metadata": {},
   "source": [
    "Many array operations are possible. Such operations are possible via numpy too but are not as intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.line.filter(from_node=[0, 1, 2, 3, 4], to_node=[0, 1, 2, 3, 4, 5, 6, 7], mode_=\"AND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2bcd9",
   "metadata": {},
   "source": [
    "### Extended arrays\n",
    "\n",
    "Extra information can be stored along with arrays via a way described in https://power-grid-model-ds.readthedocs.io/en/stable/examples/model/grid_extensions_examples.html\n",
    "\n",
    "Note that concatenating new fields to row based arrays would be inefficient as they would need to be reconstructed before using in PGM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a7688",
   "metadata": {},
   "source": [
    "## Contingency Analysis with timeseries\n",
    "\n",
    "Here we perform a selective contingency analysis on specific branches for all timesteps.\n",
    "\n",
    "Use graph operations to find top 5 ranked branches which most nodes depend on.\n",
    "\n",
    "(Assumption: Grid is radial and nodes are assigned with from_ndoe at source side.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ca4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines with most most number of dependent nodes\n",
    "n_contingencies = 5\n",
    "\n",
    "all_branches = []\n",
    "for node in grid.node.id:\n",
    "    paths = grid.graphs.active_graph.get_all_paths(ext_start_node_id=..., ext_end_node_id=...)\n",
    "    for path in paths:\n",
    "        all_branches += [(path[idx], path[idx + 1]) for idx in range(len(path) - 1)]\n",
    "\n",
    "print(f\"Path list with length {len(all_branches)}\")\n",
    "print(all_branches)\n",
    "\n",
    "counts = Counter(all_branches)\n",
    "top_branches_from_to_counts = counts.most_common(n=...)\n",
    "nodes_from = [i[0][0] for i in top_branches_from_to_counts]\n",
    "nodes_to = [i[0][1] for i in top_branches_from_to_counts]\n",
    "\n",
    "top_branches_id = grid.line.filter(from_node=..., to_node=..., mode_=\"AND\").id\n",
    "\n",
    "print(f\"top {n_contingencies} branches {top_branches_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32149652",
   "metadata": {},
   "source": [
    "Design batches for simulation in PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combos_contingencies = 1 - np.eye(..., dtype=np.uint8)\n",
    "\n",
    "line_update = initialize_array(\n",
    "    DatasetType.update,\n",
    "    ComponentType.line,\n",
    "    (... * ..., ...),\n",
    ")\n",
    "line_update[\"id\"] = top_branches_id\n",
    "line_update_reshaped = line_update.reshape(n_contingencies, n_timestamps, n_contingencies)\n",
    "line_update_reshaped[\"from_status\"] = combos_contingencies[:, np.newaxis, :]\n",
    "line_update_reshaped[\"to_status\"] = combos_contingencies[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7589b",
   "metadata": {},
   "source": [
    "Run contingency analysis on timeseries by using Timeseries data from earlier cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afaaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_profile_combined = initialize_array(\n",
    "    DatasetType.update,\n",
    "    ComponentType.sym_load,\n",
    "    (n_contingencies * n_timestamps, n_loads),\n",
    ")\n",
    "\n",
    "load_profile_combined[\"p_specified\"] = np.broadcast_to(\n",
    "    profile, (n_contingencies, n_timestamps, n_loads)\n",
    ").reshape(-1, n_loads)\n",
    "# Alternatively:\n",
    "# load_profile_combined[\"p_specified\"].reshape(n_contingencies, n_timestamps, n_loads)[:] = profile\n",
    "\n",
    "load_profile_combined[\"q_specified\"] = 0.0\n",
    "\n",
    "update_data_combined = {\n",
    "    ComponentType.line: line_update,\n",
    "    ComponentType.sym_load: load_profile_combined,\n",
    "}\n",
    "\n",
    "with Timer(\"Batch Calculation with contingencies and load profiles\"):\n",
    "    output_data_combined = model.calculate_power_flow(\n",
    "        update_data=update_data_combined,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        output_component_types=limit_related_output,\n",
    "        threading=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73a578",
   "metadata": {},
   "source": [
    "Plot loading on first line for all situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output_data_combined[ComponentType.line][\"loading\"][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d863a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del output_data_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe04047",
   "metadata": {},
   "source": [
    "#### Question regarding topology caching\n",
    "\n",
    "Instead of designing the simulation like we did in this way:\n",
    "\n",
    "```\n",
    "1 0 0 0 timestep 1\n",
    "1 0 0 0 timestep 2\n",
    "1 0 0 0 timestep 3\n",
    "...\n",
    "\n",
    "0 1 0 0 timestep 1\n",
    "0 1 0 0 timestep 2\n",
    "0 1 0 0 timestep 3\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "What if contingencies are designed this way?\n",
    "\n",
    "\n",
    "```\n",
    "0 1 1 1   timestep 1\n",
    "1 0 1 1\n",
    "1 1 0 1\n",
    "1 1 1 0\n",
    "\n",
    "0 1 1 1   timestep 2\n",
    "1 0 1 1\n",
    "1 1 0 1\n",
    "1 1 1 0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37750",
   "metadata": {},
   "source": [
    "Another alternative to is to cache internal state of PowerGridModel object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topology_2 = model.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8aa053",
   "metadata": {},
   "source": [
    "### Simulation design exercise\n",
    "\n",
    "* Can you give an example on how you can set up a network reconfiguration study based on the example above?\n",
    "* What graph related operations are needed?\n",
    "    * Is it possible to do those via PGM-DS?\n",
    "* What result attributes are to be checked? Do they need to be aggregated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc830d3",
   "metadata": {},
   "source": [
    "## Dynamic operating envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28763a05",
   "metadata": {},
   "source": [
    "Calculate the operating envelope for all timesteps at node 10 based on voltage limits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1a371",
   "metadata": {},
   "source": [
    "Find the sym load connected to node 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6293765",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_load_node_10 = grid.sym_load.filter(node=10).id\n",
    "sym_load_node_10_idx = model.get_indexer(ids=sym_load_node_10, component_type=ComponentType.sym_load)[0]\n",
    "print(sym_load_node_10_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a77c96",
   "metadata": {},
   "source": [
    "* Create a grid of P and Q values between a max and minimum range.\n",
    "* Create multiple timeseries for each point in the grid\n",
    "* Add the values in the grid to the load at node 10. Rest timeseries would remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_p = -1e7\n",
    "max_p = 1e7\n",
    "min_q = -1e7\n",
    "max_q = 1e7\n",
    "resolution = 11\n",
    "\n",
    "p_linear_values = np.linspace(start=..., stop=..., num=...)\n",
    "q_linear_values = np.linspace(start=..., stop=..., num=...)\n",
    "\n",
    "p_values, q_values = np.meshgrid(p_linear_values, q_linear_values, copy=False)\n",
    "print(f\"p_values shape: {p_values.shape}\") # Prints: (resolution, resolution)\n",
    "print(f\"q_values shape: {q_values.shape}\") # Prints: (resolution, resolution)\n",
    "\n",
    "p_envelope = np.tile(profile, (resolution, resolution, 1, 1))\n",
    "print(f\"p_envelope shape: {p_envelope.shape}\") # Prints: (resolution, resolution, n_timestamps, n_loads)\n",
    "\n",
    "p_envelope[:, :, :, sym_load_node_10_idx] += p_values[..., ..., ...]\n",
    "\n",
    "q_envelope = np.zeros(p_envelope.shape)\n",
    "q_envelope[:, :, :, sym_load_node_10_idx] += q_values[..., ..., ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e58c8",
   "metadata": {},
   "source": [
    "Create update data and run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data_envelope = {\n",
    "    ComponentType.sym_load: {\n",
    "        \"p_specified\": p_envelope.reshape(..., ...),\n",
    "        \"q_specified\": q_envelope.reshape(..., ...),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a152a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"Batch Calculation with grid of P and Q to calculate an envelope of operation\"):\n",
    "    output_data_envelope = model.calculate_power_flow(\n",
    "        update_data=update_data_envelope,\n",
    "        calculation_method=CalculationMethod.newton_raphson,\n",
    "        output_component_types=limit_related_output,\n",
    "        threading=0\n",
    "    )\n",
    "\n",
    "nodal_voltages = output_data_envelope[ComponentType.node][\"u_pu\"].reshape(..., ..., ..., ...)\n",
    "print(f\"nodal_voltages shape: {nodal_voltages.shape}\")  # Prints: (resolution, resolution, n_timestamps, n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b602c5",
   "metadata": {},
   "source": [
    "Next Step to calculate the envelope:\n",
    "\n",
    "* Calculate the index mask where the voltage does not cross above or below the voltage limit for each timestep\n",
    "* Apply this mask on the grid of P and Q for each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a298bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_low_lim = 0.95\n",
    "u_high_lim = 1.03\n",
    "\n",
    "max_voltage_scenario = np.max(nodal_voltages, axis=...) > ...\n",
    "min_voltage_scenario = np.min(nodal_voltages, axis=...) < ...\n",
    "points_outside_limits =  np.logical_or(max_voltage_scenario, min_voltage_scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70460504",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(points_outside_limits[:,:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d4c20",
   "metadata": {},
   "source": [
    "### Simulation Design Exercise\n",
    "\n",
    "* Can you give anadditional examples of calculating flexibility envelopes? Maybe with more details? (based on technical limits and not economic ones) \n",
    "* What result attributes are to be checked? Do they need to be aggregated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cfc8d4",
   "metadata": {},
   "source": [
    "# Additional Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4016b",
   "metadata": {},
   "source": [
    "#### Additional simulation design exercise\n",
    "\n",
    "* Can you give an example of how we can implement a control related action via PGM? \n",
    "* Draw a block diagram of the control?\n",
    "    * Is this scheme efficient?\n",
    "    * How do we create batches for such simulation. \n",
    "* What result attributes are to be checked? Do they need to be aggregated?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-grid-model-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
